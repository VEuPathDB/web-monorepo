#!/usr/bin/perl
use strict;
use Getopt::Long;
use Time::Local;

my ($threshold, $genepage, $notgenepage, $width_filter, $time_filter, $sort_column, $plotOutputFile, $qOrW, $logTailSize, $logDeathImmunity, %earliest, %latest, %count);

$sort_column=2;
&GetOptions('s=s' => \$threshold,
            'g' => \$genepage,
            'n' => \$notgenepage,
            'w=s' => \$width_filter,
            't=s' => \$time_filter,
            'c=s' => \$sort_column,
            'p=s' => \$plotOutputFile,
            'q=s' => \$qOrW,
            'l=s' => \$logTailSize,
            'i' => \$logDeathImmunity,
            );


usage() unless ($qOrW eq "q" or $qOrW eq "w");

my ($width_min, $width_max);
if ($width_filter) {
  ($width_min, $width_max) = split(/,\s*/, $width_filter);
}

my ($time_min, $time_max);
if ($time_filter) {
  ($time_min, $time_max) = split(/,\s*/, $time_filter);
  print "\nTime filter start: " . localtime($time_min) . " ($time_min)\n";
  print   "Time filter end:   " . localtime($time_max) . " ($time_max)\n" if $time_max;
  print "\n";
}

# QUERYTIME       Fri Mar 12 22:26:49 2010        1268450809.72195        v       Segment.pm      7.12     5792    alignment:dbEST
my $h;

if ($plotOutputFile) {
  open(P, ">$plotOutputFile") || die "Can't open plot output file '$plotOutputFile'\n";
}

my $min_absolute_time = 1000000000000000;
my $max_absolute_time = 0;

for (my $campus = 2; $campus <= 2; $campus++) { # should be 1, 2
    # print "files from campus $campus\n";
    my $server = "$qOrW$campus.cryptodb.org";
    open REMOTE_LS, "ssh $server ls /var/www/Common/tmp/gbrowseLogs/$qOrW$campus.*.org/*_slow.log |"
         or die "couldn't open ssh command to list files";
    while (my $logFileName = <REMOTE_LS> ) {
	chomp($logFileName);
	# print "    $logFileName\n";
	open LOGFILE, "ssh $qOrW$campus.cryptodb.org cat $logFileName |"
	  or die "couldn't open ssh command to cat logfile";

	while(<LOGFILE>) {
	  next unless /QUERYTIME/;
	  next if /\=\=/;  # some lines in the log are mangled, with missing newlines
	  # the symptom is that the next log entry is mashed in
	  # these are delimited by ========, so dodge that
	  next if ($genepage && !/GENEPAGE/);
	  next if ($notgenepage && /GENEPAGE/);
	  chomp;
	  my ($qt, $timestamp, $absoluteTime, $tag, $module, $seconds, $width, $name) = split(/\t/);
	  next if ($time_min && $absoluteTime < $time_min);
	  next if ($time_max && $absoluteTime > $time_max);
	  next if ($width_min && $width < $width_min);
	  next if ($width_max && $width > $width_max);
	  next if ($absoluteTime =~ /[a-z,A-Z]/); # this happened: the "time" field had a word embedded in it

          # update per-file statistics
          $earliest{$logFileName} = $absoluteTime if (!$earliest{$logFileName} || $absoluteTime < $earliest{$logFileName});
          $latest{$logFileName} = $absoluteTime if (!$latest{$logFileName} || $absoluteTime > $latest{$logFileName});
          $count{$logFileName}++;
	  $min_absolute_time = $absoluteTime if $absoluteTime < $min_absolute_time;  # the first time we have included
	  $max_absolute_time = $absoluteTime if $absoluteTime > $max_absolute_time;  # the latest time we have included

	  if (!$h->{$name}) {
	    $h->{$name} = [$name, 0, 0, 0, 0, 0, $server, $logFileName];
	  }
	  $h->{$name}->[1] += $seconds;      # total secs
	  $h->{$name}->[2] += 1;             # count
	  if ($seconds > $threshold) {
	    $h->{$name}->[3] += $seconds;    # total secs over threshold
	    $h->{$name}->[4] += 1;           # count over threshold
	  }

	  if ($seconds > $h->{$name}->[5]) { # slowest instance yet of this query name
	    $h->{$name}->[5] = $seconds; # max run-time
	    $h->{$name}->[6] = $server;  # server with max run-time
	    $h->{$name}->[7] = $logFileName; # logfile containing max run-time
	  }

	  # if we are generating a plot data file, spit out this data point
	  if ($plotOutputFile) {
	    print P "$absoluteTime\t$seconds\t$name\n";
	  }
	}
      }
  }

close(P) if ($plotOutputFile);

my @sorted = sort {$b->[$sort_column-1] <=> $a->[$sort_column-1]} values(%$h);


# name total_secs count avg_secs total_secs_over count_over  worst_secs
  print sprintf("%3s %47s%12s%8s%10s%12s%8s%7s%25s%80s\n",('  #', 'Name','TotSecs','Count','AvgSecs','SlowSecs','Slow_#','Worst', 'Server', 'Log File'));

my $rownum;
foreach my $a (@sorted) {
  my $avg = $a->[1] / $a->[2];
  print sprintf("%3d %47s%12.2f%8d%10.2f%12.2f%8d%7.2f%25s%80s\n",++$rownum,($a->[0],$a->[1],$a->[2],$avg,$a->[3],$a->[4],$a->[5],$a->[6],$a->[7]));
}

print "\nActual time start: " . localtime($min_absolute_time) . " ($min_absolute_time)\n";
print   "Actual time end:   " . localtime($max_absolute_time) . " ($max_absolute_time)\n\n";

print "statistics by log file:\n";
print sprintf("%7s %24s %24s %13s %60s\n", "queries", "--------earliest----", "---------latest-----", "page-requests", "-------------------------------file------------");
foreach my $f (sort(keys %count)) {
  $f =~ /(\w\w.\w*.org)/;
  my $server = $1;
  #print "found server \"$server\" in file \"$f\"\n";
  my $pageRequestCount = getPageViews($server, $earliest{$f}, $latest{$f}, $logTailSize, $logDeathImmunity);
  print sprintf("%7d %24s %24s %13d %60s\n", $count{$f}, scalar(localtime($earliest{$f})), scalar(localtime($latest{$f})), $pageRequestCount, $f);
}

sub getPageViews {
  my ($server, $startTime, $endTime, $logTailSize, $logDeathImmunity) = @_;

  die "endTime $endTime is less than startTime $startTime"
    if $endTime < $startTime;

  my $logTailSize = 200000 if !$logTailSize;
  open LOGFILE, "ssh $server tail -$logTailSize /var/log/httpd/$server/access_log |"
    or die "couldn't open ssh command to cat logfile";

  my $minAbsoluteTime = 1000000000000000;
  my $maxAbsoluteTime = -1;
  my $uniquePerPage = 'GET /gbrowse/tmp/\w+aa';
  my $genePageCount;

  while(<LOGFILE>) {
    m|\[(\d\d)/(\w\w\w)/(\d\d\d\d)\:(\d\d)\:(\d\d)\:(\d\d) ...... "(.*)"$|;
    my ($mday, $mon_str, $year, $hour, $min, $sec, $command) = ($1, $2, $3, $4, $5, $6, $7);
    my $months = {Jan=>0, Feb=>1, Mar=>2, Apr=>3, May=>4, Jun=>5, Jul=>6, Aug=>7, Sep=>8, Oct=>9, Nov=>10, Dec=>11};
    my $day_str = "$mday, $mon_str, $year";
    my $mon = $months->{$mon_str};
    my $absoluteTime = timelocal($sec,$min,$hour,$mday,$mon,$year);

    $minAbsoluteTime = $absoluteTime if $absoluteTime < $minAbsoluteTime;  # the first time we have included
    $maxAbsoluteTime = $absoluteTime if $absoluteTime > $maxAbsoluteTime;  # the latest time we have included

    $genePageCount++ if ($absoluteTime > $startTime && $absoluteTime < $endTime && $command =~ /$uniquePerPage/);
  }

  # print "$genePageCount gene pages between " . localtime($startTime) . " and " . localtime($endTime) . "\n";

  # check that log file covers entire period of interest
  # if this dies, consider setting a larger $logTailSize, or overriding with $logDeathImmunity
  die "access log (" . localtime($minAbsoluteTime) . " to "
    . localtime($maxAbsoluteTime) .  ") doesn't cover entire period of interest ("
      . localtime($startTime) . " to " . localtime($endTime) .  ")"
	if ($minAbsoluteTime > $startTime || $maxAbsoluteTime < $endTime)
           && !$logDeathImmunity;

  return $genePageCount;

}

sub usage {
  print STDERR "

Print a report summarizing the gbrowse slow query logs.

Takes one or more logs on standard input.

usage:  gbrowseSlowQueryReport -q {q|w} [-s secs] [-g] [-n] [-w width_min[,length_max]] [-t starttime[,endtime]] [-c colnum] [-p plotOutputFile]

where:
  -q:  show [q]a or [w]ww sites
  -s:  slowness threshold in seconds.  run times over secs are reported in Slow columns
  -g:  genepage only flag. only include queries logged with \"GENEPAGE\"
  -n:  not-genepage flag. complementary to -g flag (only non-genepage queries)
  -w:  width filter
  -t:  time filter (use seconds since epoch, which is a column in gbrowse log)
  -c:  column to sort on (default is 2, the total time)
  -p:  optional output file: a tab delimited file to pass as input
        to wdkSlowQueryPlot.  Used to visualize the query durations over time.
  -l:  log tail size -- number of records of access log to analyze for

";
  exit(1);
}
